{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8e09b4-d614-441a-b0ce-0139369ef394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glass': 195, 'metal': 417, 'other': 834, 'paper': 485, 'plastic': 2096}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import os, glob\n",
    "\n",
    "root = Path(\"data/newdata\")\n",
    "counts = {d.name: len([p for p in glob.glob(str(d/'*')) if p.lower().endswith(('.jpg','.jpeg','.png','.bmp'))])\n",
    "          for d in sorted([p for p in root.iterdir() if p.is_dir()], key=lambda x: x.name)}\n",
    "counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66cc713-efd3-4fa6-949b-d4501ded6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob, random, json, numpy as np, cv2\n",
    "from collections import Counter\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from joblib import dump\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATA_DIR   = Path(\"data/newdata\")  # class folders: glass/metal/other/paper/plastic\n",
    "MODELS_DIR = Path(\"models\");  MODELS_DIR.mkdir(exist_ok=True)\n",
    "REPORTS_DIR= Path(\"reports\"); REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "IMG_SIZE   = (160,160)\n",
    "HOG_PARAMS = dict(orientations=9, pixels_per_cell=(8,8),\n",
    "                  cells_per_block=(3,3), block_norm=\"L2-Hys\",\n",
    "                  transform_sqrt=True, feature_vector=True)\n",
    "\n",
    "\n",
    "MIN_PER_CLASS = 140   # target per class after balancing (lower = faster)\n",
    "MAX_PER_CLASS = 300   \n",
    "\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "def list_images(root):\n",
    "    per = {}\n",
    "    for d in sorted([p for p in root.iterdir() if p.is_dir()], key=lambda x:x.name):\n",
    "        files = []\n",
    "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.JPG\",\"*.PNG\",\"*.JPEG\",\"*.BMP\"):\n",
    "            files.extend(glob.glob(str(d / ext)))\n",
    "        per[d.name] = files\n",
    "    return per\n",
    "\n",
    "def preprocess(bgr):\n",
    "    bgr = cv2.GaussianBlur(bgr, (3,3), 0)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L,A,B = cv2.split(lab)\n",
    "    L = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(L)\n",
    "    return cv2.cvtColor(cv2.merge([L,A,B]), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def hog_color(bgr):\n",
    "    img = cv2.resize(bgr, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    feats = []\n",
    "    for ch in cv2.split(rgb):\n",
    "        feats.extend(hog(ch, **HOG_PARAMS))\n",
    "    return np.asarray(feats, np.float32)\n",
    "\n",
    "def hog_edge(bgr):\n",
    "    img = cv2.resize(bgr, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ed = cv2.Canny(gray, 80, 160)\n",
    "    return hog(ed, **HOG_PARAMS).astype(np.float32)\n",
    "\n",
    "def hsv_hist(bgr, bins=(16, 16, 16)):\n",
    "    img = cv2.resize(bgr, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv],[0,1,2],None,bins,[0,180, 0,256, 0,256])\n",
    "    hist = cv2.normalize(hist, None).flatten().astype(np.float32)\n",
    "    return hist\n",
    "\n",
    "def light_aug(bgr):\n",
    "    if random.random() < 0.5:\n",
    "        bgr = cv2.flip(bgr, 1)\n",
    "    if random.random() < 0.5:\n",
    "        alpha = 1.0 + (random.random()*0.25 - 0.125)\n",
    "        beta  = int(random.random()*20 - 10)\n",
    "        bgr = cv2.convertScaleAbs(bgr, alpha=alpha, beta=beta)\n",
    "    return bgr\n",
    "\n",
    "per = list_images(DATA_DIR)\n",
    "print(\"Raw:\", {k: len(v) for k,v in per.items()})\n",
    "\n",
    "X, y = [], []\n",
    "for cls, files in per.items():\n",
    "    files = files.copy(); random.shuffle(files)\n",
    "    # undersample\n",
    "    files = files[:MAX_PER_CLASS]\n",
    "    # oversample up to MIN_PER_CLASS\n",
    "    while len(files) < MIN_PER_CLASS and files:\n",
    "        files.append(random.choice(files))\n",
    "    for fp in files:\n",
    "        img = cv2.imread(fp)\n",
    "        if img is None: continue\n",
    "        img = preprocess(img)\n",
    "        if files.count(fp) > 1:\n",
    "            img = light_aug(img)\n",
    "        f = np.concatenate([hog_color(img), hog_edge(img), hsv_hist(img)], axis=0)\n",
    "        X.append(f); y.append(cls)\n",
    "\n",
    "X = np.stack(X).astype(np.float32); y = np.array(y)\n",
    "print(\"Balanced (FAST):\", X.shape, Counter(y))\n",
    "\n",
    "le = LabelEncoder(); y_enc = le.fit_transform(y)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "Xtr_s = scaler.fit_transform(Xtr); Xte_s = scaler.transform(Xte)\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", C=5, gamma=\"scale\", probability=True,\n",
    "          class_weight=\"balanced\", random_state=42)\n",
    "svm.fit(Xtr_s, ytr)\n",
    "\n",
    "print(classification_report(yte, svm.predict(Xte_s), target_names=le.classes_, zero_division=0))\n",
    "cm = confusion_matrix(yte, svm.predict(Xte_s))\n",
    "plt.figure(figsize=(6,6)); plt.imshow(cm, cmap=\"Blues\"); plt.title(\"Confusion Matrix (FAST)\")\n",
    "plt.xticks(range(len(le.classes_)), le.classes_, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(le.classes_)), le.classes_)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout(); plt.savefig(REPORTS_DIR/\"cm_hog_svm_stronger_FAST.png\", dpi=150); plt.close()\n",
    "\n",
    "bundle = {\n",
    "    \"scaler\": scaler, \"svm\": svm, \"label_encoder\": le,\n",
    "    \"img_size\": IMG_SIZE, \"hog_params\": HOG_PARAMS,\n",
    "    \"classes\": list(le.classes_), \"feature_mode\": \"color_edge_hist\"\n",
    "}\n",
    "dump(bundle, MODELS_DIR/\"recycle_hog_svm.joblib\")\n",
    "with open(MODELS_DIR/\"model_meta.json\", \"w\") as f:\n",
    "    json.dump({\"classes\": list(le.classes_), \"img_size\": IMG_SIZE, \"feature_mode\": \"color_edge_hist\"}, f, indent=2)\n",
    "\n",
    "print(\"Saved ->\", MODELS_DIR / \"recycle_hog_svm.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ae5daa-5fa1-422a-9bd2-50053dd62db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ['glass' 'metal' 'other' 'paper' 'plastic']\n",
      "feature_mode: color_edge_hist\n",
      "img_size: (160, 160)\n",
      "expected n_features: 109072\n",
      "glass -> [('glass', 0.9389533269981982), ('other', 0.018539975971327758), ('paper', 0.016490179222848077)]\n",
      "paper -> [('other', 0.5914534255259039), ('plastic', 0.19984699629314015), ('paper', 0.10484693730931591)]\n",
      "plastic -> [('other', 0.7052492698031848), ('plastic', 0.12519324048584926), ('glass', 0.07457886019014824)]\n",
      "metal -> [('metal', 0.9395071844647885), ('plastic', 0.02823487849412246), ('paper', 0.019023285535574266)]\n",
      "other -> [('glass', 0.2772578947394055), ('other', 0.2717839482235699), ('plastic', 0.2594807199931873)]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob, cv2\n",
    "from src.classifier import HogSvmClassifier\n",
    "\n",
    "clf = HogSvmClassifier(\"models/recycle_hog_svm.joblib\")\n",
    "print(\"Loaded:\", clf.classes)\n",
    "print(\"feature_mode:\", clf.feature_mode)\n",
    "print(\"img_size:\", clf.img_size)\n",
    "print(\"expected n_features:\", getattr(clf.scaler, \"n_features_in_\", None))\n",
    "\n",
    "for cls in [\"glass\",\"paper\",\"plastic\",\"metal\",\"other\"]:\n",
    "    cands = []\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.JPG\",\"*.PNG\"):\n",
    "        cands.extend(glob.glob(str(Path(\"data/newdata\")/cls/ext)))\n",
    "    if not cands:\n",
    "        print(\"No images for\", cls)\n",
    "        continue\n",
    "    img = cv2.imread(cands[0])\n",
    "    assert img is not None, f\"Failed to load image for {cls}\"\n",
    "    preds = clf.topk(img, k=3)\n",
    "    print(cls, \"->\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc175db-3da6-4437-8951-26776b37b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ['glass' 'metal' 'other' 'paper' 'plastic'] | feature_mode: color_edge_hist | img_size: (160, 160)\n",
      "Testing with: data\\newdata\\plastic\\1001_2987_plastic.jpg\n",
      "Image shape: (91, 57, 3)\n",
      "Top-3: [('other', 0.7052492698031848), ('plastic', 0.12519324048584926), ('glass', 0.07457886019014824)]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "from src.classifier import HogSvmClassifier\n",
    "\n",
    "\n",
    "clf = HogSvmClassifier(\"models/recycle_hog_svm.joblib\")\n",
    "print(\"Loaded:\", clf.classes, \"| feature_mode:\", clf.feature_mode, \"| img_size:\", clf.img_size)\n",
    "\n",
    "\n",
    "root = Path(\"data/newdata/plastic\")\n",
    "cands = []\n",
    "for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.JPG\",\"*.PNG\"):\n",
    "    cands.extend(root.glob(ext))\n",
    "\n",
    "if not cands:\n",
    "    raise FileNotFoundError(f\"No image files found in {root}. Put at least one image there.\")\n",
    "\n",
    "img_path = cands[0]        \n",
    "print(\"Testing with:\", img_path)\n",
    "\n",
    "\n",
    "img = cv2.imread(str(img_path))\n",
    "if img is None or img.size == 0:\n",
    "    raise ValueError(f\"cv2.imread failed for {img_path}\")\n",
    "\n",
    "print(\"Image shape:\", img.shape)\n",
    "\n",
    "\n",
    "print(\"Top-3:\", clf.topk(img, k=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886849f3-faf8-40cb-99d2-448d2191a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\envs\\recyclecv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ['glass' 'metal' 'other' 'paper' 'plastic'] | feature_mode: color_edge_hist | img_size: (160, 160)\n",
      "Testing with: data\\newdata\\plastic\\1001_2987_plastic.jpg\n",
      "Image shape: (91, 57, 3)\n",
      "Top-3: [('other', 0.7052492698031848), ('plastic', 0.12519324048584926), ('glass', 0.07457886019014824)]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "from src.classifier import HogSvmClassifier\n",
    "\n",
    "\n",
    "clf = HogSvmClassifier(\"models/recycle_hog_svm.joblib\")\n",
    "print(\"Loaded:\", clf.classes, \"| feature_mode:\", clf.feature_mode, \"| img_size:\", clf.img_size)\n",
    "\n",
    "\n",
    "folder = Path(\"data/newdata/plastic\")          # try \"paper\", \"glass\", etc.\n",
    "cands = []\n",
    "for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.JPG\",\"*.PNG\"):\n",
    "    cands.extend(folder.glob(ext))\n",
    "\n",
    "if not cands:\n",
    "    raise FileNotFoundError(f\"No image files found under {folder}\")\n",
    "\n",
    "img_path = cands[0]\n",
    "print(\"Testing with:\", img_path)\n",
    "\n",
    "\n",
    "img = cv2.imread(str(img_path))\n",
    "if img is None or img.size == 0:\n",
    "    raise ValueError(f\"cv2.imread failed for {img_path}\")\n",
    "\n",
    "print(\"Image shape:\", img.shape)\n",
    "\n",
    "\n",
    "print(\"Top-3:\", clf.topk(img, k=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4bd5070-f3ef-4e49-a2d9-9866f43bf78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: {'glass': 390, 'metal': 834, 'other': 1668, 'paper': 970, 'plastic': 4192}\n",
      "Balanced (FAST): (1130, 109072) Counter({'other': 250, 'glass': 220, 'metal': 220, 'paper': 220, 'plastic': 220})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       glass       0.59      0.59      0.59        44\n",
      "       metal       0.54      0.43      0.48        44\n",
      "       other       0.44      0.72      0.55        50\n",
      "       paper       0.50      0.34      0.41        44\n",
      "     plastic       0.37      0.30      0.33        44\n",
      "\n",
      "    accuracy                           0.48       226\n",
      "   macro avg       0.49      0.48      0.47       226\n",
      "weighted avg       0.49      0.48      0.47       226\n",
      "\n",
      "Saved text report and cm.npy in reports\n",
      "Saved -> models\\recycle_hog_svm.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import glob, random, json\n",
    "import numpy as np, cv2\n",
    "from collections import Counter\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from joblib import dump\n",
    "\n",
    "DATA_DIR   = Path(\"data/newdata\")  # glass/metal/other/paper/plastic\n",
    "MODELS_DIR = Path(\"models\");  MODELS_DIR.mkdir(exist_ok=True)\n",
    "REPORTS_DIR= Path(\"reports\"); REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "IMG_SIZE   = (160,160)\n",
    "HOG_PARAMS = dict(orientations=9, pixels_per_cell=(8,8),\n",
    "                  cells_per_block=(3,3), block_norm=\"L2-Hys\",\n",
    "                  transform_sqrt=True, feature_vector=True)\n",
    "\n",
    "TARGET_PER_CLASS = 220\n",
    "MAX_OTHER        = 250\n",
    "\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "def list_images(root):\n",
    "    per = {}\n",
    "    for d in sorted([p for p in root.iterdir() if p.is_dir()], key=lambda x:x.name):\n",
    "        files = []\n",
    "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.JPG\",\"*.PNG\",\"*.JPEG\",\"*.BMP\"):\n",
    "            files.extend(glob.glob(str(d / ext)))\n",
    "        per[d.name] = files\n",
    "    return per\n",
    "\n",
    "def preprocess(bgr):\n",
    "    bgr = cv2.GaussianBlur(bgr, (3,3), 0)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L,A,B = cv2.split(lab)\n",
    "    L = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(L)\n",
    "    return cv2.cvtColor(cv2.merge([L,A,B]), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def hog_color(bgr):\n",
    "    img = cv2.resize(bgr, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    feats = []\n",
    "    for ch in cv2.split(rgb):\n",
    "        feats.extend(hog(ch, **HOG_PARAMS))\n",
    "    return np.asarray(feats, np.float32)\n",
    "\n",
    "def hog_edge(bgr):\n",
    "    img = cv2.resize(bgr, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ed = cv2.Canny(gray, 80, 160)\n",
    "    return hog(ed, **HOG_PARAMS).astype(np.float32)\n",
    "\n",
    "def hsv_hist(bgr, bins=(16, 16, 16)):\n",
    "    img = cv2.resize(bgr, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv],[0,1,2],None,bins,[0,180, 0,256, 0,256])\n",
    "    hist = cv2.normalize(hist, None).flatten().astype(np.float32)\n",
    "    return hist\n",
    "\n",
    "def light_aug(bgr):\n",
    "    if random.random() < 0.5: bgr = cv2.flip(bgr, 1)\n",
    "    if random.random() < 0.5:\n",
    "        alpha = 1.0 + (random.random()*0.25 - 0.125)\n",
    "        beta  = int(random.random()*20 - 10)\n",
    "        bgr = cv2.convertScaleAbs(bgr, alpha=alpha, beta=beta)\n",
    "    return bgr\n",
    "\n",
    "per = list_images(DATA_DIR)\n",
    "print(\"Raw:\", {k: len(v) for k,v in per.items()})\n",
    "if not per:\n",
    "    raise SystemExit(\"No class folders in data/newdata\")\n",
    "\n",
    "X, y = [], []\n",
    "for cls, files in per.items():\n",
    "    files = files.copy(); random.shuffle(files)\n",
    "    cap = MAX_OTHER if cls.lower()==\"other\" else TARGET_PER_CLASS\n",
    "    files = files[:cap]\n",
    "    while len(files) < TARGET_PER_CLASS and files:\n",
    "        files.append(random.choice(files))\n",
    "    for fp in files:\n",
    "        img = cv2.imread(fp)\n",
    "        if img is None: continue\n",
    "        img = preprocess(img)\n",
    "        if files.count(fp) > 1: img = light_aug(img)\n",
    "        f = np.concatenate([hog_color(img), hog_edge(img), hsv_hist(img)], axis=0)\n",
    "        X.append(f); y.append(cls)\n",
    "\n",
    "X = np.stack(X).astype(np.float32); y = np.array(y)\n",
    "print(\"Balanced (FAST):\", X.shape, Counter(y))\n",
    "\n",
    "\n",
    "le = LabelEncoder(); y_enc = le.fit_transform(y)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "Xtr_s = scaler.fit_transform(Xtr); Xte_s = scaler.transform(Xte)\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", C=5, gamma=\"scale\", probability=True,\n",
    "          class_weight=\"balanced\", random_state=42)\n",
    "svm.fit(Xtr_s, ytr)\n",
    "\n",
    "report = classification_report(yte, svm.predict(Xte_s), target_names=le.classes_, zero_division=0)\n",
    "print(report)\n",
    "cm = confusion_matrix(yte, svm.predict(Xte_s))\n",
    "np.save(REPORTS_DIR/\"cm.npy\", cm)\n",
    "with open(REPORTS_DIR/\"classification_report.txt\",\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report)\n",
    "print(\"Saved text report and cm.npy in\", REPORTS_DIR)\n",
    "\n",
    "bundle = {\n",
    "    \"scaler\": scaler, \"svm\": svm, \"label_encoder\": le,\n",
    "    \"img_size\": IMG_SIZE, \"hog_params\": HOG_PARAMS,\n",
    "    \"classes\": list(le.classes_), \"feature_mode\": \"color_edge_hist\",\n",
    "    \"calib_weights\": [1.05 if c in (\"plastic\",\"paper\") else (0.82 if c==\"other\" else 1.0)\n",
    "                      for c in le.classes_]\n",
    "}\n",
    "dump(bundle, MODELS_DIR/\"recycle_hog_svm.joblib\")\n",
    "with open(MODELS_DIR/\"model_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"classes\": list(le.classes_), \"img_size\": IMG_SIZE,\n",
    "               \"feature_mode\": \"color_edge_hist\",\n",
    "               \"calib_weights\": bundle[\"calib_weights\"]}, f, indent=2)\n",
    "print(\"Saved ->\", MODELS_DIR / \"recycle_hog_svm.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:recyclecv]",
   "language": "python",
   "name": "conda-env-recyclecv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
